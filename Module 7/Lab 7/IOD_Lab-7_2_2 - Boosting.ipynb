{"cells":[{"cell_type":"markdown","metadata":{"id":"GPQokKfGrpu_"},"source":["<div>\n","<img src=https://www.institutedata.com/wp-content/uploads/2019/10/iod_h_tp_primary_c.svg width=\"300\">\n","</div>"]},{"cell_type":"markdown","metadata":{"id":"2ibB1lPorpvB"},"source":["# Lab 7.2.2: Boosting\n","\n","INSTRUCTIONS:\n","\n","- Read the guides and hints then create the necessary analysis and code to find an answer and conclusion for the scenario below.\n","- The baseline results (minimum) are:\n","    - **Accuracy** = 0.9429\n","    - **ROC AUC**  = 0.9333\n","- Try to achieve better results!"]},{"cell_type":"markdown","metadata":{"id":"dDHEDe2TrpvE"},"source":["# Foreword\n","It is common that companies and professionals start with the data immediately available. Although this approach works, ideally the first step is to identify the problem or question and only then identify and obtain the set of data that can help to solve or answer the problem.\n","\n","Also, given the current abundance of data, processing power and some particular machine learning methods, there could be a temptation to use ALL the data available. **Quality** is _**better**_ than **Quantity**!\n","\n","Part of calling this discipline **Data Science** is that it is supposed to follow a process and not reach conclusions without support from evidence.\n","\n","Moreover, it is a creative, exploratory, laborious and iterative process. It is part of the process to repeat, review and change when finding a dead-end."]},{"cell_type":"markdown","metadata":{"id":"LqafjJWZrpvG"},"source":["## Scenario: Predicting Breast Cancer\n","The dataset you are going to be using for this laboratory is popularly known as the **Wisconsin Breast Cancer** dataset (`breast-cancer-wisconsin-data-old.csv`). The task related to it is Classification.\n","\n","The dataset contains a total number of _10_ features labelled in either **benign** or **malignant** classes. The features have _699_ instances out of which _16_ feature values are missing. The dataset only contains numeric values."]},{"cell_type":"markdown","metadata":{"id":"vaxdobIZrpvI"},"source":["# Step 1: Define the problem or question\n","Identify the subject matter and the given or obvious questions that would be relevant in the field.\n","\n","## Potential Questions\n","List the given or obvious questions.\n","\n","## Actual Question\n","Choose the **one** question that should be answered."]},{"cell_type":"markdown","metadata":{"id":"-O8FhgglrpvL"},"source":["# Step 2: Find the Data\n","### Wisconsin Breast Cancer DataSet\n","- **Citation Request**\n","\n","    This breast cancer databases was obtained from the **University of Wisconsin Hospitals**, **Madison** from **Dr. William H. Wolberg**. If you publish results when using this database, then please include this information in your acknowledgements.\n","\n","- **Title**\n","\n","    Wisconsin Breast Cancer Database (January 8, 1991)\n","\n","- **Sources**\n","    - **Creator**\n","            Dr. William H. Wolberg (physician)\n","            University of Wisconsin Hospitals\n","            Madison, Wisconsin\n","            USA\n","    - **Donor**\n","            Olvi Mangasarian (mangasarian@cs.wisc.edu)\n","            Received by David W. Aha (aha@cs.jhu.edu)\n","    - **Date**\n","            15 July 1992\n","        \n","### UCI - Machine Learning Repository\n","- Center for Machine Learning and Intelligent Systems\n","\n","The [**UCI Machine Learning Repository**](http://archive.ics.uci.edu/about) is a collection of databases, domain theories, and data generators that are used by the machine learning community for the empirical analysis of machine learning algorithms."]},{"cell_type":"markdown","metadata":{"id":"MT-Jy4rurpvN"},"source":["# Step 3: Read the Data\n","- Read the data\n","- Perform some basic structural cleaning to facilitate the work"]},{"cell_type":"markdown","metadata":{"id":"ui6EbpzKrpvO"},"source":["# Step 4: Explore and Clean the Data\n","- Perform some initial simple **EDA** (Exploratory Data Analysis)\n","- Check for\n","    - **Number of features**\n","    - **Data types**\n","    - **Domains, Intervals**\n","    - **Outliers** (are they valid or spurious data [read or measure errors])\n","    - **Null** (values not present or coded [as zero of empty strings])\n","    - **Missing Values** (coded [as zero of empty strings] or values not present)\n","    - **Coded content** (classes identified by numbers or codes to represent absence of data)"]},{"cell_type":"markdown","metadata":{"id":"djEFyiAvrpvP"},"source":["# Step 5: Prepare the Data\n","- Deal with the data as required by the modelling technique\n","    - **Outliers** (remove or adjust if possible or necessary)\n","    - **Null** (remove or interpolate if possible or necessary)\n","    - **Missing Values** (remove or interpolate if possible or necessary)\n","    - **Coded content** (transform if possible or necessary [str to number or vice-versa])\n","    - **Normalisation** (if possible or necessary)\n","    - **Feature Engineer** (if useful or necessary)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","from xgboost import XGBClassifier\n","import lightgbm as lgb\n","from catboost import CatBoostClassifier\n","\n","seed=42"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Import the data we cleaned previously \n","df = pd.read_csv(\"breast_cancer_cleaned.csv\")"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 699 entries, 0 to 698\n","Data columns (total 11 columns):\n"," #   Column                       Non-Null Count  Dtype  \n","---  ------                       --------------  -----  \n"," 0   Sample_number                699 non-null    float64\n"," 1   Clump_Thickness              699 non-null    float64\n"," 2   Cell_Size_Uniformity         699 non-null    float64\n"," 3   Cell_Shape_Uniformity        699 non-null    float64\n"," 4   Marginal_Adhesion            699 non-null    float64\n"," 5   Single_Epithelial_Cell_Size  699 non-null    float64\n"," 6   Bare_Nuclei                  699 non-null    float64\n"," 7   Bland_Chromatin              699 non-null    float64\n"," 8   Normal_Nucleoli              699 non-null    float64\n"," 9   Mitoses                      699 non-null    float64\n"," 10  Class                        699 non-null    float64\n","dtypes: float64(11)\n","memory usage: 60.2 KB\n"]}],"source":["# Scale the data using MinMaxScaler\n","df_s = df.copy()\n","scaler = MinMaxScaler()\n","df_s = scaler.fit_transform(df_s)\n","df_s = pd.DataFrame(df_s, columns=df.columns)\n","\n","df_s.info()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sample_number</th>\n","      <th>Clump_Thickness</th>\n","      <th>Cell_Size_Uniformity</th>\n","      <th>Cell_Shape_Uniformity</th>\n","      <th>Marginal_Adhesion</th>\n","      <th>Single_Epithelial_Cell_Size</th>\n","      <th>Bare_Nuclei</th>\n","      <th>Bland_Chromatin</th>\n","      <th>Normal_Nucleoli</th>\n","      <th>Mitoses</th>\n","      <th>Class</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.070067</td>\n","      <td>0.444444</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.111111</td>\n","      <td>0.000000</td>\n","      <td>0.222222</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.070285</td>\n","      <td>0.444444</td>\n","      <td>0.333333</td>\n","      <td>0.333333</td>\n","      <td>0.444444</td>\n","      <td>0.666667</td>\n","      <td>1.000000</td>\n","      <td>0.222222</td>\n","      <td>0.111111</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.071217</td>\n","      <td>0.222222</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.111111</td>\n","      <td>0.111111</td>\n","      <td>0.222222</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.071281</td>\n","      <td>0.555556</td>\n","      <td>0.777778</td>\n","      <td>0.777778</td>\n","      <td>0.000000</td>\n","      <td>0.222222</td>\n","      <td>0.333333</td>\n","      <td>0.222222</td>\n","      <td>0.666667</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.071336</td>\n","      <td>0.333333</td>\n","      <td>0.000000</td>\n","      <td>0.000000</td>\n","      <td>0.222222</td>\n","      <td>0.111111</td>\n","      <td>0.000000</td>\n","      <td>0.222222</td>\n","      <td>0.000000</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Sample_number  Clump_Thickness  Cell_Size_Uniformity  \\\n","0       0.070067         0.444444              0.000000   \n","1       0.070285         0.444444              0.333333   \n","2       0.071217         0.222222              0.000000   \n","3       0.071281         0.555556              0.777778   \n","4       0.071336         0.333333              0.000000   \n","\n","   Cell_Shape_Uniformity  Marginal_Adhesion  Single_Epithelial_Cell_Size  \\\n","0               0.000000           0.000000                     0.111111   \n","1               0.333333           0.444444                     0.666667   \n","2               0.000000           0.000000                     0.111111   \n","3               0.777778           0.000000                     0.222222   \n","4               0.000000           0.222222                     0.111111   \n","\n","   Bare_Nuclei  Bland_Chromatin  Normal_Nucleoli  Mitoses  Class  \n","0     0.000000         0.222222         0.000000      0.0    0.0  \n","1     1.000000         0.222222         0.111111      0.0    0.0  \n","2     0.111111         0.222222         0.000000      0.0    0.0  \n","3     0.333333         0.222222         0.666667      0.0    0.0  \n","4     0.000000         0.222222         0.000000      0.0    0.0  "]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df_s.head()"]},{"cell_type":"markdown","metadata":{"id":"u_uEHN4zrpvQ"},"source":["# Step 6: Modelling\n","Refer to the Problem and Main Question.\n","- What are the input variables (features)?\n","- Is there an output variable (label)?\n","- If there is an output variable:\n","    - What is it?\n","    - What is its type?\n","- What type of Modelling is it?\n","    - [ ] Supervised\n","    - [ ] Unsupervised\n","- What type of Modelling is it?\n","    - [ ] Regression\n","    - [ ] Classification (binary)\n","    - [ ] Classification (multi-class)\n","    - [ ] Clustering"]},{"cell_type":"markdown","metadata":{"id":"7_-BoWumrpvR"},"source":["# Step 7: Split the Data\n","\n","Need to check for **Supervised** modelling:\n","- Number of known cases or observations\n","- Define the split in Training/Test or Training/Validation/Test and their proportions\n","- Check for unbalanced classes and how to keep or avoid it when splitting"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Split the data into training and test sets \n","X = df_s.drop(columns=[\"Class\"])\n","y = df_s[\"Class\"]\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=seed)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"i8IjhjqtrpvT"},"source":["# Step 8: Define and Fit Models\n","\n","Define the model and its hyper-parameters.\n","\n","Consider the parameters and hyper-parameters of each model at each (re)run and after checking the efficiency of a model against the training and test datasets."]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=None, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=None, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=None, n_jobs=None,\n","              num_parallel_tree=None, random_state=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=None, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=None, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=None, n_jobs=None,\n","              num_parallel_tree=None, random_state=None, ...)</pre></div></div></div></div></div>"],"text/plain":["XGBClassifier(base_score=None, booster=None, callbacks=None,\n","              colsample_bylevel=None, colsample_bynode=None,\n","              colsample_bytree=None, device=None, early_stopping_rounds=None,\n","              enable_categorical=False, eval_metric=None, feature_types=None,\n","              gamma=None, grow_policy=None, importance_type=None,\n","              interaction_constraints=None, learning_rate=None, max_bin=None,\n","              max_cat_threshold=None, max_cat_to_onehot=None,\n","              max_delta_step=None, max_depth=None, max_leaves=None,\n","              min_child_weight=None, missing=nan, monotone_constraints=None,\n","              multi_strategy=None, n_estimators=None, n_jobs=None,\n","              num_parallel_tree=None, random_state=None, ...)"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["# Train the XGBClassifier model\n","xgb_model = XGBClassifier()\n","\n","xgb_model.fit(X_train, y_train)\n"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["[LightGBM] [Info] Number of positive: 174, number of negative: 315\n","[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001193 seconds.\n","You can set `force_row_wise=true` to remove the overhead.\n","And if memory is not enough, you can set `force_col_wise=true`.\n","[LightGBM] [Info] Total Bins 249\n","[LightGBM] [Info] Number of data points in the train set: 489, number of used features: 10\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.355828 -> initscore=-0.593517\n","[LightGBM] [Info] Start training from score -0.593517\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n","[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"]}],"source":["# Prepare the data for LGBM\n","lgb_train = lgb.Dataset(X_train, label=y_train)\n","lgb_test = lgb.Dataset(X_test, label=y_test)\n","\n","# Set the parameters for LGBM\n","params = {\n","    'objective': 'binary', \n","    'metric': 'binary_error'\n","}\n","\n","# Train the LGBM model \n","num_rounds = 100\n","lgb_model = lgb.train(params, lgb_train, num_rounds, valid_sets=[lgb_test])"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["<catboost.core.CatBoostClassifier at 0x18d19879210>"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# Train the Catboost model \n","cat_model = CatBoostClassifier(iterations=100, learning_rate=0.1, depth=6)\n","\n","cat_model.fit(X_train, y_train, eval_set=(X_test, y_test), verbose=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"eL5-13AgrpvU"},"source":["# Step 9: Verify and Evaluate the Training Model\n","- Use the **training** data to make predictions\n","- What metrics are appropriate for the modelling approach used\n","- For **Supervised** models:\n","    - Check the **Training Results** with the **Training Predictions** during development\n","- Analyse, modify the parameters and hyper-parameters and repeat (within reason) until the model does not improve"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["XGB train accuracy:  1.0\n","XGB test accuracy:  0.9714285714285714\n","\n","\n","LGBM train accuracy:  1.0\n","LGBM test accuracy:  0.9619047619047619\n","\n","\n","Catboost train accuracy:  0.9897750511247444\n","Catboost test accuracy:  0.9666666666666667\n"]}],"source":["# Evaluate the model's train accuracy \n","\n","# XGB accuracy \n","xgb_train_preds = xgb_model.predict(X_train)\n","xgb_train_accuracy = accuracy_score(y_train, xgb_train_preds)\n","\n","# LGB accuracy \n","lgb_train_pred_prob = lgb_model.predict(X_train)\n","lgb_train_preds = [1 if x > 0.5 else 0 for x in lgb_train_pred_prob]\n","lgb_train_accuracy = accuracy_score(y_train, lgb_train_preds)\n","\n","# Catboost accuracy \n","cat_train_preds = cat_model.predict(X_train)\n","cat_train_accuracy = accuracy_score(y_train, cat_train_preds)\n","\n","\n","\n","# Evaluate the models test accuracy\n","\n","# XGB accuracy \n","xgb_preds = xgb_model.predict(X_test)\n","xgb_accuracy = accuracy_score(y_test, xgb_preds)\n","\n","# LGB accuracy \n","lgb_pred_prob = lgb_model.predict(X_test)\n","lgb_preds = [1 if x > 0.5 else 0 for x in lgb_pred_prob]\n","lgb_accuracy = accuracy_score(y_test, lgb_preds)\n","\n","# Catboost accuracy \n","cat_preds = cat_model.predict(X_test)\n","cat_accuracy = accuracy_score(y_test, cat_preds)\n","\n","\n","# Print the results \n","\n","print(\"XGB train accuracy: \", xgb_train_accuracy)\n","print(\"XGB test accuracy: \", xgb_accuracy)\n","\n","print(\"\\n\\nLGBM train accuracy: \", lgb_train_accuracy)\n","print(\"LGBM test accuracy: \", lgb_accuracy)\n","\n","print(\"\\n\\nCatboost train accuracy: \", cat_train_accuracy)\n","print(\"Catboost test accuracy: \", cat_accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"nOf1r-RIrpvV"},"source":["# Step 10: Make Predictions and Evaluate the Test Model\n","**NOTE**: **Do this only after not making any more improvements in the model**.\n","\n","- Use the **test** data to make predictions\n","- For **Supervised** models:\n","    - Check the **Test Results** with the **Test Predictions**"]},{"cell_type":"markdown","metadata":{"id":"j8y6lKh2rpvW"},"source":["# Step 11: Solve the Problem or Answer the Question\n","The results of an analysis or modelling can be used:\n","- As part of a product or process, so the model can make predictions when new input data is available\n","- As part of a report including text and charts to help understand the problem\n","- As input for further questions"]},{"cell_type":"markdown","metadata":{"id":"RERADKgNFq9T"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n","> > > > > > > > > © 2024 Institute of Data\n","\n","\n","---\n","\n","\n","\n","---\n","\n","\n","\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
